{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "81338c05-7f91-40d8-a02c-41d72fa6d3c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows, Columns: (30000, 24)\n",
      "\n",
      "Fraud label counts:\n",
      "fraud_reported\n",
      "N    26560\n",
      "Y     3440\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Fraud rate: 0.1147\n",
      "\n",
      "Top missing columns:\n",
      "authorities_contacted          0.252133\n",
      "policy_id                      0.000000\n",
      "policy_state                   0.000000\n",
      "total_claim_amount             0.000000\n",
      "claim_amount                   0.000000\n",
      "police_report_available        0.000000\n",
      "witnesses                      0.000000\n",
      "bodily_injuries                0.000000\n",
      "number_of_vehicles_involved    0.000000\n",
      "incident_hour_of_the_day       0.000000\n",
      "dtype: float64\n",
      "\n",
      "Average total claim amount by fraud label:\n",
      "fraud_reported\n",
      "N    12768.44124\n",
      "Y    12675.08682\n",
      "Name: total_claim_amount, dtype: float64\n",
      "\n",
      "Fraud rate by incident_type:\n",
      "incident_type\n",
      "Vehicle Theft               0.117794\n",
      "Single Vehicle Collision    0.115707\n",
      "Multi-vehicle Collision     0.115543\n",
      "Parked Car                  0.109479\n",
      "Name: fraud_reported, dtype: float64\n",
      "\n",
      "Fraud rate by collision_type:\n",
      "collision_type\n",
      "Rear       0.114988\n",
      "Side       0.114864\n",
      "Unknown    0.114489\n",
      "Front      0.114324\n",
      "Name: fraud_reported, dtype: float64\n",
      "\n",
      "Fraud rate by police_report_available:\n",
      "police_report_available\n",
      "No     0.116630\n",
      "Yes    0.112677\n",
      "Name: fraud_reported, dtype: float64\n",
      "\n",
      "Confusion matrix:\n",
      "[[4777  535]\n",
      " [ 559  129]]\n",
      "\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8952    0.8993    0.8973      5312\n",
      "           1     0.1943    0.1875    0.1908       688\n",
      "\n",
      "    accuracy                         0.8177      6000\n",
      "   macro avg     0.5448    0.5434    0.5440      6000\n",
      "weighted avg     0.8149    0.8177    0.8163      6000\n",
      "\n",
      "ROC-AUC: 0.6265\n",
      "\n",
      "Model saved to: mini_outputs/fraud_logreg_pipeline.joblib\n"
     ]
    }
   ],
   "source": [
    "# Mini Project: Auto Insurance Fraud Prediction\n",
    "# ---------------------------------------------\n",
    "# Goal:\n",
    "# Use past insurance claims to predict whether a claim is fraudulent or not.\n",
    "# This script loads the data, does a few simple checks, trains a model,\n",
    "# and shows how well it performs.\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix, classification_report, roc_auc_score\n",
    "\n",
    "from joblib import dump\n",
    "\n",
    "# NOTE: Need to change your path, if running code on your own device\n",
    "# Load the data\n",
    "DATA_PATH = r\"C:\\Users\\kevin\\Downloads\\car_insurance_fraud_dataset.csv\"\n",
    "TARGET = \"fraud_reported\"   # Y = fraud, N = not fraud\n",
    "\n",
    "df = pd.read_csv(DATA_PATH)\n",
    "\n",
    "# Clean up the target column\n",
    "df[TARGET] = df[TARGET].astype(str).str.strip().str.upper()\n",
    "\n",
    "print(\"Rows, Columns:\", df.shape)\n",
    "print(\"\\nFraud label counts:\")\n",
    "print(df[TARGET].value_counts())\n",
    "\n",
    "fraud_rate = (df[TARGET] == \"Y\").mean()\n",
    "print(\"\\nFraud rate:\", round(fraud_rate, 4))\n",
    "\n",
    "\n",
    "# Simple data checks\n",
    "# Check which columns have missing values\n",
    "missing = df.isna().mean().sort_values(ascending=False).head(10)\n",
    "print(\"\\nTop missing columns:\")\n",
    "print(missing)\n",
    "\n",
    "# Compare average claim amounts if the column exists\n",
    "if \"total_claim_amount\" in df.columns:\n",
    "    print(\"\\nAverage total claim amount by fraud label:\")\n",
    "    print(df.groupby(TARGET)[\"total_claim_amount\"].mean())\n",
    "\n",
    "# Look at fraud rates for a few useful categorical columns\n",
    "for col in [\"incident_type\", \"collision_type\", \"police_report_available\"]:\n",
    "    if col in df.columns:\n",
    "        print(f\"\\nFraud rate by {col}:\")\n",
    "        print(\n",
    "            df.groupby(col)[TARGET]\n",
    "              .apply(lambda x: (x == \"Y\").mean())\n",
    "              .sort_values(ascending=False)\n",
    "              .head(8)\n",
    "        )\n",
    "\n",
    "\n",
    "# Prepare data for modeling\n",
    "# Remove ID-like columns (they don't help prediction)\n",
    "id_columns = [\n",
    "    \"policy_number\",\n",
    "    \"claim_id\",\n",
    "    \"customer_id\",\n",
    "    \"insured_zip\",\n",
    "    \"incident_location\"\n",
    "]\n",
    "\n",
    "df = df.drop(columns=[c for c in id_columns if c in df.columns], errors=\"ignore\")\n",
    "\n",
    "X = df.drop(columns=[TARGET])\n",
    "y = (df[TARGET] == \"Y\").astype(int)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# Separate numeric and categorical columns\n",
    "num_cols = X.select_dtypes(include=[np.number]).columns.tolist()\n",
    "cat_cols = [c for c in X.columns if c not in num_cols]\n",
    "\n",
    "# Fill missing values and encode categories\n",
    "preprocess = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", Pipeline([\n",
    "            (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "            (\"scaler\", StandardScaler())\n",
    "        ]), num_cols),\n",
    "\n",
    "        (\"cat\", Pipeline([\n",
    "            (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "            (\"onehot\", OneHotEncoder(handle_unknown=\"ignore\"))\n",
    "        ]), cat_cols)\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "# Train the model\n",
    "model = LogisticRegression(\n",
    "    max_iter=2000,\n",
    "    class_weight=\"balanced\"  # helps with class imbalance\n",
    ")\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    (\"preprocess\", preprocess),\n",
    "    (\"model\", model)\n",
    "])\n",
    "\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "# Evaluate the model\n",
    "predictions = pipeline.predict(X_test)\n",
    "probabilities = pipeline.predict_proba(X_test)[:, 1]\n",
    "\n",
    "print(\"\\nConfusion matrix:\")\n",
    "print(confusion_matrix(y_test, predictions))\n",
    "\n",
    "print(\"\\nClassification report:\")\n",
    "print(classification_report(y_test, predictions, digits=4))\n",
    "\n",
    "print(\"ROC-AUC:\", round(roc_auc_score(y_test, probabilities), 4))\n",
    "\n",
    "\n",
    "# Save the trained model\n",
    "os.makedirs(\"mini_outputs\", exist_ok=True)\n",
    "dump(pipeline, \"mini_outputs/fraud_logreg_pipeline.joblib\")\n",
    "\n",
    "print(\"\\nModel saved to: mini_outputs/fraud_logreg_pipeline.joblib\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ab212a7-b86c-462b-aeb2-c9c7d7285a69",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28526b04-9873-4834-952a-36469804eea1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
